================================================================================
TUTORIAL 1: CHECKING STRINGS - APPLICATION CHECKLIST
================================================================================

[_/] I completed the tutorial exercises


CONNECTING TO MY DATA:
----------------------

1. Did I identify any string-related questions in my Week 1 questions list?

   [ _/] YES - Question #(s): question one, found repeats of factor names for the same things e.g. High_dose and HIGH_DOSE
   [ ] NO - Skip to question 4


2. If YES, which technique from this tutorial could help address my question?

   [ ] str_to_lower() - standardize capitalization
   [ ] str_to_upper() - standardize capitalization  
   [ ] str_trim() - remove leading/trailing whitespace
   [ ] str_replace() - fix typos or inconsistent spellings
   [ _/] Other: because there are mutliple slightly different character strings for the same variable, while str_to_upper would help for some, its best to use distinct() to find all of the names, then use case_when to change all but one, so all variables have the exact same identifier 
   [ ] None of these apply


3. Show what this technique would DO to my data:

   Variable name: _Medium_dose_
   
   Example values BEFORE:
   - Medium_dose
   - MEDIUM_DOSE
   - 
   
   What they would become AFTER:
   - Medium_dose
   - 
   - 


4. If this tutorial is NOT relevant to my data:

   Why not? (Check all that apply)
   [ ] I don't have any character/text variables
   [ ] My text variables are already clean
   [ ] My string issues are different from what this tutorial covers
   [ ] Other: ___________


================================================================================


================================================================================
TUTORIAL 2: CHECKING DATES - APPLICATION CHECKLIST
================================================================================

[_/ ] I completed the tutorial exercises



CONNECTING TO MY DATA:
----------------------

1. Did I identify any date-related questions in my Week 1 questions list?

   [ ] YES - Question #(s): ___________
   [ _/] NO - Skip to question 5


2. If YES, which technique from this tutorial could help address my question?

   [ ] dmy() / ymd() / mdy() - parse dates in different formats
   [ ] excel_numeric_to_date() - convert Excel serial numbers
   [ ] Checking for impossible dates (wrong day/month/year)
   [ ] Other: ___________
   [ ] None of these apply


3. Show what this technique would DO to my data:

   Variable name: ___________
   
   Example values BEFORE:
   - 
   - 
   - 
   
   What they would become AFTER:
   - 
   - 
   - 


4. Think about consequences:

   What assumption am I making about date format?
   (e.g., "01/12/2023 is DD/MM/YYYY not MM/DD/YYYY")
   
   
   What could go wrong if this assumption is incorrect?
   
   
   How could I verify my assumption is correct?
   


5. If this tutorial is NOT relevant to my data:

   Why not?
   [ ] I don't have any date variables
   [_/ ] My dates are already in proper format - yet to see any need to change the dates
   [ ] My date issues are different from what this tutorial covers
   [ ] Other: ___________


================================================================================


================================================================================
TUTORIAL 3: CHECKING MISSING DATA PATTERNS - APPLICATION CHECKLIST
================================================================================

[_/] I completed the tutorial exercises


CONNECTING TO MY DATA:
----------------------

1. Did I identify any missing data questions in my Week 1 questions list?

   [_/] YES - Question #(s): Why are there NAs for body mass, and the number of eggs hatched and laid?
   [ ] NO - But I'll check anyway (missing data is common)


2. Which variables have the most missing data?

   Variable: comments | Percent missing: 84%
   Variable: delta_13_c_o_oo | Percent missing: 4%
   Variable: delta_15_c_o_oo | Percent missing: 4%


3. Missingness types checklist


   [_/] MCAR (Missing Completely At Random) - appears random/scattered
   [ ] MAR (Missing At Random) - related to other observed variables
   [_/] MNAR (Missing Not At Random) - related to the missing value itself

Why is it important to know what type of missing data we have? 

so we can remove bias from our analysis. Missing data can often be due to other factors,
therefore should be considered when determining if data related to those NAs should be kept

================================================================================


================================================================================
TUTORIAL 4: CHECKING DUPLICATES - APPLICATION CHECKLIST
================================================================================

[_/] I completed the tutorial exercises


CONNECTING TO MY DATA:
----------------------

1. Did I identify any duplicate-related questions in my Week 1 questions list?

   [_/] YES - Question #(s): Why are there duplicates for some of the records?
   [ ] NO - But I'll check anyway


3. Think about consequences:

   If I remove duplicates, what am I assuming?
   
   
   If duplicates are actually repeated measures, what should I do instead?
   [ ] Keep them - they're legitimate observations
   [_/] Flag them for later analysis that accounts for non-independence
   [ ] Other: ___________
   
   
================================================================================


================================================================================
TUTORIAL 5: NUMERIC & CROSS-VARIABLE CONSISTENCY - APPLICATION CHECKLIST
================================================================================

[_/] I completed the tutorial exercises


PART A: NUMERIC PLAUSIBILITY
-----------------------------

1. Did I identify any numeric plausibility questions in my Week 1 questions list?

   [_/] YES - Question #(s): How is there a negative body mass?
   [ ] NO - Skip to Part B


2. If YES, which numeric variable looks suspicious?

   Variable name: body_mass_g
   
   Minimum value: -93  | Is this biologically possible? [ ] Yes [X] No [ ] Unsure
   Maximum value: 108.71  | Is this biologically possible? [ ] Yes [ ] No [X] Unsure
   

   Why do these look wrong?
   [X] Negative value (impossible for this measurement)
   [ ] Zero (should be NA instead)
   [ ] Too large (exceeds known biological maximum)
   [ ] Too small (below known biological minimum)
   [ ] Possible units confusion (mixed kg and g?)
   [ ] Other: ___________



PART B: CROSS-VARIABLE CONSISTENCY
-----------------------------------

4. Did I identify any cross-variable questions in my Week 1 questions list?

   [ ] YES - Question #(s): ___________
   [X] NO - But I'll check anyway


5. Choose TWO variables that should be related (e.g., body length and body mass,
   sex and reproductive status, species and location):

   Variable 1: eggs_laid
   Variable 2: eggs_hatched
   
   What relationship do I expect between them?
   [ ] Positive correlation (both increase together)
   [ ] Negative correlation (one increases, other decreases)
   [X] Biological constraint (certain combinations impossible)
   [ ] Spatial constraint (certain combinations shouldn't occur)
   [ ] Other: ___________
   
   Describe the expected relationship:
    fewer eggs hatched than were laid. There should be no instance where more eggs hatched than were laid


6. Think about consequences:

   If these variables are inconsistent, what should I do?
   [X] Remove the observations
   [ ] Convert one variable to NA (which one? _________)
   [X] Flag for review but keep both
   [X] Query the data collector
   [ ] Other: ___________
   
   Justification:
    Inconsistencies may suggest incorrect gathering of data, 
    or possible contamination due to other factors. 
    Therefore, its best to find the cause of the inconsistency if possible, 
    so it can be factored in.
    Regardless, using inconsistent data will cause problems for any analysis that has them,
    and keeping track, especially if there are many, 
    makes it more likely to keep them within the data set due to human error. 
    Unless the data collecter can determine which variable is incorrect, it is impossible to 
    guarantee the variable you are keeping will be accurate.
    Therefore, removing the incorrect values is best since it prevents any incorrect values from
    entering the analysis.
    
================================================================================